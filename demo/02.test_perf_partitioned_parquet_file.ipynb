{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:40:22.662337Z",
     "start_time": "2025-01-28T10:40:22.368921Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, year\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced482640a1fddc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:40:28.994773Z",
     "start_time": "2025-01-28T10:40:22.873428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/03 14:03:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"ReadWriteParquet\") \\\n",
    "                  .config(\"spark.sql.legacy.parquet.nanosAsLong\", \"true\") \\\n",
    "                  .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0ee13031602dd",
   "metadata": {},
   "source": [
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a348b81de98149",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:40:31.869753Z",
     "start_time": "2025-01-28T10:40:31.853040Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent / \"data\"\n",
    "\n",
    "fr_immo_raw_path = (data_path / \"fr_immo_transactions.parquet\").as_posix()\n",
    "fr_immo_valid_path = (data_path / \"fr_immo_transactions_valid_ts.parquet\").as_posix()\n",
    "\n",
    "fr_immo_simple_partition_path = (data_path / \"fr_immo_transactions_dep_partition\").as_posix()\n",
    "\n",
    "fr_immo_multi_partition_path = (data_path / \"fr_immo_transactions_multi_partition\").as_posix()\n",
    "\n",
    "fr_immo_csv_path = (data_path / \"fr_immo_transactions.csv\").as_posix()\n",
    "\n",
    "date_col_name = \"date_transaction\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdfdea55a8f6d1",
   "metadata": {},
   "source": [
    "## Performance test csv vs parquet\n",
    "\n",
    "In this part, we will test the query performance between csv and parquet.\n",
    "\n",
    "\n",
    "1. read(data loading)\n",
    "2. row_counts\n",
    "3. group_by\n",
    "4. filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61674d40",
   "metadata": {},
   "source": [
    "### Read parquet vs read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66637272e90694c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:40:49.974599Z",
     "start_time": "2025-01-28T10:40:44.724698Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.69 ms, sys: 3.72 ms, total: 7.4 ms\n",
      "Wall time: 2.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fr_immo_parquet_df = spark.read.parquet(fr_immo_valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f731af15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 ms, sys: 222 µs, total: 22.2 ms\n",
      "Wall time: 26.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fr_immo_csv_df = spark.read.option(\"header\",True).option(\"inferSchema\", True).csv(fr_immo_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe4a06",
   "metadata": {},
   "source": [
    "> You can notice read a csv file is ten times longer than read a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4261ab89b32bb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:41:10.194247Z",
     "start_time": "2025-01-28T10:41:08.828952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.13 ms, total: 3.13 ms\n",
      "Wall time: 871 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read a single partitioned parquet\n",
    "fr_immo_simple_part= spark.read.parquet(fr_immo_simple_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cbf0b297e59ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:41:29.765402Z",
     "start_time": "2025-01-28T10:41:28.423076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 ms, sys: 0 ns, total: 2.71 ms\n",
      "Wall time: 818 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read a multiple partitioned parquet file\n",
    "fr_immo_multi_part= spark.read.parquet(fr_immo_multi_partition_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522a307",
   "metadata": {},
   "source": [
    "### Count row number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3716c9e802314b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T16:08:00.793837Z",
     "start_time": "2025-01-27T16:07:59.883583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count rows with parquet: 9141573\n",
      "CPU times: user 1.81 ms, sys: 136 µs, total: 1.95 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"count rows with parquet: {fr_immo_parquet_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c49dd1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count rows with parquet: 9141573\n",
      "CPU times: user 12.1 ms, sys: 0 ns, total: 12.1 ms\n",
      "Wall time: 2.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"count rows with parquet: {fr_immo_csv_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb5e34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a5a53e626f1f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T16:08:02.872427Z",
     "start_time": "2025-01-27T16:08:02.864356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count rows with single partitioned parquet: 9141573\n",
      "CPU times: user 1.96 ms, sys: 0 ns, total: 1.96 ms\n",
      "Wall time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"count rows with single partitioned parquet: {fr_immo_parquet_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4129f6eee302c3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:47:06.191266Z",
     "start_time": "2025-01-28T10:46:38.225890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count rows with multiple partitioned parquet: 9141573\n",
      "CPU times: user 2.17 ms, sys: 0 ns, total: 2.17 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"count rows with multiple partitioned parquet: {fr_immo_parquet_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa2bc0dc97b71e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T16:09:31.019185Z",
     "start_time": "2025-01-27T16:09:29.645569Z"
    }
   },
   "source": [
    "### Group by query performence test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2608af003801764e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T16:09:57.197248Z",
     "start_time": "2025-01-27T16:09:57.190693Z"
    }
   },
   "outputs": [],
   "source": [
    "batiment_typ_col_name = \"type_batiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ce5108baeceb71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T16:10:00.849637Z",
     "start_time": "2025-01-27T16:10:00.166126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group by type_batiment and count rows with parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|type_batiment|  count|\n",
      "+-------------+-------+\n",
      "|  Appartement|4079137|\n",
      "|       Maison|5062436|\n",
      "+-------------+-------+\n",
      "\n",
      "CPU times: user 6.27 ms, sys: 489 µs, total: 6.76 ms\n",
      "Wall time: 1.35 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"group by type_batiment and count rows with parquet\")\n",
    "fr_immo_parquet_df.groupby(batiment_typ_col_name).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d74c966018b76af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T16:10:12.658824Z",
     "start_time": "2025-01-27T16:10:06.477530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group by type_batiment and count rows with csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|type_batiment|  count|\n",
      "+-------------+-------+\n",
      "|  Appartement|4079137|\n",
      "|       Maison|5062436|\n",
      "+-------------+-------+\n",
      "\n",
      "CPU times: user 10.7 ms, sys: 4.29 ms, total: 15 ms\n",
      "Wall time: 8.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f\"group by type_batiment and count rows with csv\")\n",
    "fr_immo_csv_df.groupby(batiment_typ_col_name).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64f5052fafaa34",
   "metadata": {},
   "source": [
    "### Filter query performence test\n",
    "\n",
    "In the first filter query scenario, the filter query matches well with our partition architecture. You can notice the more we partition the best the performence is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea9c951602b5c290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:47:41.870166Z",
     "start_time": "2025-01-28T10:47:41.320981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vente appartement in parquet without partition: 202414\n",
      "CPU times: user 5.83 ms, sys: 0 ns, total: 5.83 ms\n",
      "Wall time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_departement = 92\n",
    "target_type_batiment= \"Appartement\"\n",
    "\n",
    "total_transaction = fr_immo_parquet_df.filter((col(\"departement\") == target_departement) & (col(\"type_batiment\")==target_type_batiment)).count()\n",
    "print(f\"Total vente appartement in parquet without partition: {total_transaction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7241ca4bbfe8c94e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:47:48.287026Z",
     "start_time": "2025-01-28T10:47:44.482748Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vente appartement in csv: 202414\n",
      "CPU times: user 11.2 ms, sys: 0 ns, total: 11.2 ms\n",
      "Wall time: 6.69 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_transaction = fr_immo_csv_df.filter((col(\"departement\") == target_departement) & (col(\"type_batiment\")==target_type_batiment)).count()\n",
    "print(f\"Total vente appartement in csv: {total_transaction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d996aea57d1a0cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:49:07.524364Z",
     "start_time": "2025-01-28T10:49:07.148165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vente appartement in parquet with signle partition: 202414\n",
      "CPU times: user 3.76 ms, sys: 0 ns, total: 3.76 ms\n",
      "Wall time: 269 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_transaction = fr_immo_simple_part.filter((col(\"departement\") == target_departement) & (col(\"type_batiment\")==target_type_batiment)).count()\n",
    "print(f\"Total vente appartement in parquet with signle partition: {total_transaction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "842193bde63d9314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:49:32.589673Z",
     "start_time": "2025-01-28T10:49:32.348225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vente appartement in parquet with multiple partition: 202414\n",
      "CPU times: user 4.2 ms, sys: 371 µs, total: 4.57 ms\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_transaction = fr_immo_multi_part.filter((col(\"departement\") == target_departement) & (col(\"type_batiment\")==target_type_batiment)).count()\n",
    "print(f\"Total vente appartement in parquet with multiple partition: {total_transaction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aa784e5d862bd",
   "metadata": {},
   "source": [
    "### Do a filter which does not match the partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c4c07577e4d3fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:54:14.621309Z",
     "start_time": "2025-01-28T10:54:14.444122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transaction montrouge: 656\n",
      "CPU times: user 3.77 ms, sys: 687 μs, total: 4.45 ms\n",
      "Wall time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "target_year =2023\n",
    "code_postal_montrouge = 92120\n",
    "\n",
    "total_transaction_montrouge = fr_immo_parquet_df.filter((col(\"code_postal\") == code_postal_montrouge) & (year(col(\"date_transaction\"))==target_year)).count()\n",
    "print(f\"Total transaction in parquet without partition: {total_transaction_montrouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e792ae6dbfbe7728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:54:10.360887Z",
     "start_time": "2025-01-28T10:54:09.998026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transaction montrouge: 656\n",
      "CPU times: user 2.25 ms, sys: 2.2 ms, total: 4.45 ms\n",
      "Wall time: 353 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_transaction_montrouge = fr_immo_simple_part.filter((col(\"code_postal\") == code_postal_montrouge) & (year(col(\"date_transaction\"))==target_year)).count()\n",
    "print(f\"Total transaction in parquet with single partition: {total_transaction_montrouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d564820ac6eab947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:54:24.062680Z",
     "start_time": "2025-01-28T10:54:23.141775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transaction montrouge: 656\n",
      "CPU times: user 2.41 ms, sys: 2.23 ms, total: 4.64 ms\n",
      "Wall time: 915 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_transaction_montrouge = fr_immo_multi_part.filter((col(\"code_postal\") == code_postal_montrouge) & (year(col(\"date_transaction\"))==target_year)).count()\n",
    "print(f\"Total transaction in parquet with multiple partition: {total_transaction_montrouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6736645c22a0ac0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T10:55:05.817845Z",
     "start_time": "2025-01-28T10:54:54.897352Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transaction montrouge: 656\n",
      "CPU times: user 21.1 ms, sys: 4.45 ms, total: 25.5 ms\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_transaction_montrouge = fr_immo_csv_df.filter((col(\"code_postal\") == code_postal_montrouge) & (year(col(\"date_transaction\"))==target_year)).count()\n",
    "print(f\"Total transaction in csv: {total_transaction_montrouge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3741e43b3b65fac",
   "metadata": {},
   "source": [
    "## Row oriented query\n",
    "\n",
    "In the below example, we will try to count distinct rows (all column values of the row are unique is considered as a unique row). It's considered as row based operation, which parquet is not designed for.\n",
    "\n",
    "But distinct value of column is considered as column base operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d2d74ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct city count(column based operation): 32320\n",
      "+-------------------+\n",
      "|              ville|\n",
      "+-------------------+\n",
      "|              CESSY|\n",
      "|DOMPIERRE-SUR-VEYLE|\n",
      "|       GRAND-CORENT|\n",
      "|            CONFORT|\n",
      "|LA NEUVILLE BOSMONT|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 4.62 ms, sys: 3.79 ms, total: 8.41 ms\n",
      "Wall time: 2.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distinct_city = fr_immo_parquet_df.select(\"ville\").distinct()\n",
    "print(f\"distinct city count(column based operation): {distinct_city.count()}\")\n",
    "distinct_city.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac149e684770408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T09:08:47.749317Z",
     "start_time": "2025-01-28T09:07:48.332254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/03 14:23:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:38 WARN TaskMemoryManager: Failed to allocate a page (33554432 bytes), try again.\n",
      "25/02/03 14:23:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:23:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct rows count(row based operation): 9141573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/03 14:24:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:04 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:07 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:09 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:10 WARN TaskMemoryManager: Failed to allocate a page (33554432 bytes), try again.\n",
      "25/02/03 14:24:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/02/03 14:24:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 63:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+-----------+--------+--------------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "|id_transaction|    date_transaction|    prix|departement|id_ville|               ville|code_postal|             adresse|type_batiment|n_pieces|surface_habitable|        latitude|       longitude|\n",
      "+--------------+--------------------+--------+-----------+--------+--------------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "|        144226|2014-01-18 10:23:...|110000.0|         01|     345|SAINT-DENIS-EN-BUGEY|       1500|  VILLAGE SAINT D...|  Appartement|       4|              100| 45.951437939058|5.32844001943718|\n",
      "|        140148|2014-01-19 10:23:...| 83600.0|         01|      53|     BOURG-EN-BRESSE|       1000|        3 RUE GOUNOD|  Appartement|       2|               50|46.1965265769704|5.22048990188062|\n",
      "|        148148|2014-01-29 10:21:...| 60000.0|         01|      34|              BELLEY|       1300|         47 AV LIVET|  Appartement|       2|               38|45.7560378151214|5.68102701973282|\n",
      "|        147862|2014-02-11 10:19:...|260000.0|         01|     289|            PERONNAS|       1960|    829 CHE DU STADE|       Maison|       5|              101|46.1826757564904|5.21267705173674|\n",
      "|        145428|2014-02-17 10:18:...|200000.0|         01|     289|            PERONNAS|       1960|361 RUE DES COLCH...|       Maison|       4|               95|46.1849246094121|5.21323008045271|\n",
      "+--------------+--------------------+--------+-----------+--------+--------------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 53.9 ms, sys: 15.4 ms, total: 69.4 ms\n",
      "Wall time: 55.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distinct_rows = fr_immo_parquet_df.distinct()\n",
    "print(f\"distinct rows count(row based operation): {distinct_rows.count()}\")\n",
    "distinct_rows.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1503a758c6475a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T09:04:57.101400Z",
     "start_time": "2025-01-28T09:04:46.464747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct city count: 32320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              ville|\n",
      "+-------------------+\n",
      "|              CESSY|\n",
      "|DOMPIERRE-SUR-VEYLE|\n",
      "|       GRAND-CORENT|\n",
      "|            CONFORT|\n",
      "|LA NEUVILLE BOSMONT|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 31.4 ms, sys: 6.81 ms, total: 38.2 ms\n",
      "Wall time: 10.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distinct_city = fr_immo_csv_df.select(\"ville\").distinct()\n",
    "print(f\"distinct city count: {distinct_city.count()}\")\n",
    "distinct_city.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d19c32f302c6fae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T09:11:05.013732Z",
     "start_time": "2025-01-28T09:09:36.525549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/28 10:09:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:09:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:09:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:09:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:09:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:06 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 48:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct rows count: 9141573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/28 10:10:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:37 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/01/28 10:10:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+-----------+--------+------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "|id_transaction|    date_transaction|    prix|departement|id_ville|       ville|code_postal|             adresse|type_batiment|n_pieces|surface_habitable|        latitude|       longitude|\n",
      "+--------------+--------------------+--------+-----------+--------+------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "|        143595|2014-01-06 10:24:...|206800.0|          1|     446|  VILLENEUVE|       1480|10 ALL DES MARGUE...|       Maison|       5|              100| 46.017215697925|4.83236118261167|\n",
      "|        146931|2014-02-24 10:17:...| 50000.0|          1|     430|    VARAMBON|       1160|      5154  VARAMBON|       Maison|       2|               56|46.0400470273731|5.31682925744396|\n",
      "|        146921|2014-02-25 10:17:...|236000.0|          1|     165|FRANCHELEINS|       1090|         5448  MOINE|       Maison|       4|              100|46.0719472966885| 4.8098449791294|\n",
      "|        139502|2014-02-26 10:17:...|160000.0|          1|     180|      GRILLY|       1220|    23 CHE DU MOULIN|       Maison|       1|               52|46.3158318720306|6.11565594496905|\n",
      "|        139061|2014-03-12 10:15:...|316000.0|          1|      10|   ANGLEFORT|       1350| 5148  SOUS LA VILLE|       Maison|       3|              142|45.9165306495878|5.81802191490142|\n",
      "+--------------+--------------------+--------+-----------+--------+------------+-----------+--------------------+-------------+--------+-----------------+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 84.9 ms, sys: 22 ms, total: 107 ms\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distinct_rows = fr_immo_csv_df.distinct()\n",
    "print(f\"distinct rows count: {distinct_rows.count()}\")\n",
    "distinct_rows.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3295c84c051cad2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T09:14:02.006676Z",
     "start_time": "2025-01-28T09:14:01.994214Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def random_batch(df:DataFrame,fmt:str):\n",
    "    start = time.time()\n",
    "    result=df.sample(False, 0.05).collect()\n",
    "    stats=\"{},{},{}\".format(fmt, \"random_batch\", time.time() - start)\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0870e375401903d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T09:14:13.195716Z",
     "start_time": "2025-01-28T09:14:03.423555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet,random_batch,9.600819110870361\n"
     ]
    }
   ],
   "source": [
    "random_batch(fr_immo_parquet_df,\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d543b2b00a31081d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T09:15:12.131728Z",
     "start_time": "2025-01-28T09:14:51.821540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv,random_batch,20.17941665649414\n"
     ]
    }
   ],
   "source": [
    "random_batch(fr_immo_csv_df,\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7885412d3dff6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7efb4e02e2afb6af",
   "metadata": {},
   "source": [
    "## Compatibility problems\n",
    "\n",
    "As there are many libraries that can write parquet files, there are some compatibility problems.\n",
    "\n",
    "### Timestamp data type\n",
    "\n",
    "The default Timestamp data type implementation in **pyarrow/pandas is INT64 (TIMESTAMP(NANOS))**.\n",
    "\n",
    "The default Timestamp data type implementation in **spark is INT64 (TIMESTAMP(MICROS)) or INT96 (NANOS)**.\n",
    "\n",
    "INT96 (NANOS) is deprecated in the newer spark version. You can still activate in Spark environments with `config(\"spark.sql.legacy.parquet.nanosAsLong\", \"true\")`\n",
    "\n",
    "In the below example, we use pyspark to read a parquet file which is generated by using the pandas/pyarrow. You may receive an error message (based on your spark version)\n",
    "\n",
    "```java\n",
    "org.apache.spark.sql.AnalysisException: Illegal Parquet type: INT64 (TIMESTAMP(NANOS,false)).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51c85c5f4ebe74ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:24:40.210827Z",
     "start_time": "2025-01-27T15:24:37.060126Z"
    }
   },
   "outputs": [],
   "source": [
    "# the raw parquet file is writen with pandas/arrow with default config\n",
    "fr_immo_raw_df = spark.read.parquet(fr_immo_raw_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dacd0b7ea2600b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:26:04.884737Z",
     "start_time": "2025-01-27T15:26:04.866374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transaction: integer (nullable = true)\n",
      " |-- date_transaction: long (nullable = true)\n",
      " |-- prix: double (nullable = true)\n",
      " |-- departement: string (nullable = true)\n",
      " |-- id_ville: integer (nullable = true)\n",
      " |-- ville: string (nullable = true)\n",
      " |-- code_postal: integer (nullable = true)\n",
      " |-- adresse: string (nullable = true)\n",
      " |-- type_batiment: string (nullable = true)\n",
      " |-- n_pieces: integer (nullable = true)\n",
      " |-- surface_habitable: integer (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can notice that the date_transaction is not conidered as timestamp type, but long type\n",
    "fr_immo_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a91bfb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|   date_transaction|\n",
      "+-------------------+\n",
      "|1388620800000000000|\n",
      "|1388620800000000000|\n",
      "|1388620800000000000|\n",
      "|1388620800000000000|\n",
      "|1388707200000000000|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fr_immo_raw_df.select([date_col_name]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "974977a2c3a78998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:28:51.899625Z",
     "start_time": "2025-01-27T15:28:51.276463Z"
    }
   },
   "outputs": [],
   "source": [
    "# the valid df is writen with the correct timestamp conf which spark can read\n",
    "fr_immo_valid_df = spark.read.parquet(fr_immo_valid_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe6500f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_transaction: integer (nullable = true)\n",
      " |-- date_transaction: timestamp (nullable = true)\n",
      " |-- prix: double (nullable = true)\n",
      " |-- departement: string (nullable = true)\n",
      " |-- id_ville: integer (nullable = true)\n",
      " |-- ville: string (nullable = true)\n",
      " |-- code_postal: integer (nullable = true)\n",
      " |-- adresse: string (nullable = true)\n",
      " |-- type_batiment: string (nullable = true)\n",
      " |-- n_pieces: integer (nullable = true)\n",
      " |-- surface_habitable: integer (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can notice that the date_transaction is conidered as timestamp type.\n",
    "fr_immo_valid_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f33060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|    date_transaction|\n",
      "+--------------------+\n",
      "|2013-12-31 10:25:...|\n",
      "|2013-12-31 10:25:...|\n",
      "|2013-12-31 10:25:...|\n",
      "|2013-12-31 10:25:...|\n",
      "|2014-01-01 10:25:...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fr_immo_valid_df.select([date_col_name]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5d95ae8d9b7f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
