{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. duckdb allows to get parquet file metadata\n",
    "\n",
    "Duckdb allows us to get various parquet file metadata. Below are some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à DuckDB\n",
    "conn = duckdb.connect(database=':memory:', read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parquet file path\n",
    "data_path = Path.cwd().parent / \"data\"\n",
    "fr_immo_raw_path = (data_path / \"fr_immo_transactions.parquet\").as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get detailed metadata of the parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de la requête : \n",
      "                                           file_name  row_group_id  \\\n",
      "0  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...             0   \n",
      "1  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...             0   \n",
      "2  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...             0   \n",
      "3  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...             0   \n",
      "4  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...             0   \n",
      "\n",
      "   row_group_num_rows  row_group_num_columns  row_group_bytes  column_id  \\\n",
      "0             1048576                     13         54792718          0   \n",
      "1             1048576                     13         54792718          1   \n",
      "2             1048576                     13         54792718          2   \n",
      "3             1048576                     13         54792718          3   \n",
      "4             1048576                     13         54792718          4   \n",
      "\n",
      "   file_offset  num_values    path_in_schema        type  ...  \\\n",
      "0            0     1048576    id_transaction       INT32  ...   \n",
      "1            0     1048576  date_transaction       INT64  ...   \n",
      "2            0     1048576              prix      DOUBLE  ...   \n",
      "3            0     1048576       departement  BYTE_ARRAY  ...   \n",
      "4            0     1048576          id_ville       INT32  ...   \n",
      "\n",
      "       stats_min_value      stats_max_value  compression  \\\n",
      "0                    1              1985836       SNAPPY   \n",
      "1  2014-01-02 00:00:00  2024-06-29 00:00:00       SNAPPY   \n",
      "2                 -0.0          641855000.0       SNAPPY   \n",
      "3                   01                   14       SNAPPY   \n",
      "4                    1                  834       SNAPPY   \n",
      "\n",
      "                    encodings index_page_offset dictionary_page_offset  \\\n",
      "0  PLAIN, RLE, RLE_DICTIONARY               NaN                      4   \n",
      "1  PLAIN, RLE, RLE_DICTIONARY               NaN                4785157   \n",
      "2  PLAIN, RLE, RLE_DICTIONARY               NaN                4991186   \n",
      "3  PLAIN, RLE, RLE_DICTIONARY               NaN                7582832   \n",
      "4  PLAIN, RLE, RLE_DICTIONARY               NaN                7583016   \n",
      "\n",
      "  data_page_offset total_compressed_size  total_uncompressed_size  \\\n",
      "0          1048657               4785153                  4784914   \n",
      "1          4810487                206029                   259738   \n",
      "2          5413878               2591646                  2819362   \n",
      "3          7582913                   184                      200   \n",
      "4          7586362               1290642                  1316179   \n",
      "\n",
      "   key_value_metadata  \n",
      "0                  {}  \n",
      "1                  {}  \n",
      "2                  {}  \n",
      "3                  {}  \n",
      "4                  {}  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# get detailed metadata of the parquet file\n",
    "result = conn.execute(f\"SELECT * FROM parquet_metadata('{fr_immo_raw_path}');\").fetchdf()\n",
    "print(\"Parquet file metadata : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Fetch the column names and column types\n",
    "\n",
    "The **DESCRIBE** function returns the traditional schema of the parquet file (e.g. column names, types, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet schema : \n",
      "        column_name   column_type null   key default extra\n",
      "0    id_transaction       INTEGER  YES  None    None  None\n",
      "1  date_transaction  TIMESTAMP_NS  YES  None    None  None\n",
      "2              prix        DOUBLE  YES  None    None  None\n",
      "3       departement       VARCHAR  YES  None    None  None\n",
      "4          id_ville       INTEGER  YES  None    None  None\n"
     ]
    }
   ],
   "source": [
    "query = f\"DESCRIBE SELECT * FROM '{fr_immo_raw_path}';\"\n",
    "result = conn.execute(query).fetchdf()\n",
    "print(\"Parquet schema : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Fetch the internal schema of a Parquet file\n",
    "\n",
    "The parquet_schema function can be used to query the internal schema contained within a Parquet file. Note that this is the schema as it is contained within the metadata of the Parquet file. It contains more detailed information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet schema : \n",
      "                                           file_name              name  \\\n",
      "0  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...            schema   \n",
      "1  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...    id_transaction   \n",
      "2  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...  date_transaction   \n",
      "3  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...              prix   \n",
      "4  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...       departement   \n",
      "\n",
      "         type type_length repetition_type  num_children converted_type  scale  \\\n",
      "0        None        None        REQUIRED          13.0           None    NaN   \n",
      "1       INT32        None        OPTIONAL           NaN           None    NaN   \n",
      "2       INT64        None        OPTIONAL           NaN           None    NaN   \n",
      "3      DOUBLE        None        OPTIONAL           NaN           None    NaN   \n",
      "4  BYTE_ARRAY        None        OPTIONAL           NaN           UTF8    NaN   \n",
      "\n",
      "   precision  field_id                                       logical_type  \n",
      "0        NaN       NaN                                               None  \n",
      "1        NaN       NaN                                               None  \n",
      "2        NaN       NaN  TimestampType(isAdjustedToUTC=0, unit=TimeUnit...  \n",
      "3        NaN       NaN                                               None  \n",
      "4        NaN       NaN                                       StringType()  \n"
     ]
    }
   ],
   "source": [
    "query = f\"SELECT * FROM parquet_schema('{fr_immo_raw_path}');\"\n",
    "result = conn.execute(query).fetchdf()\n",
    "print(\"Parquet schema : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Parquet File Metadata\n",
    "\n",
    "The parquet_file_metadata function can be used to query file-level metadata such as the format version and the encryption algorithm used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet schema : \n",
      "                                           file_name  \\\n",
      "0  /home/pliu/git/ParquetDuckDB/data/fr_immo_tran...   \n",
      "\n",
      "                         created_by  num_rows  num_row_groups  format_version  \\\n",
      "0  parquet-cpp-arrow version 19.0.0   9141573               9               2   \n",
      "\n",
      "  encryption_algorithm footer_signing_key_metadata  \n",
      "0                 None                        None  \n"
     ]
    }
   ],
   "source": [
    "query = f\"SELECT * FROM parquet_file_metadata('{fr_immo_raw_path}');\"\n",
    "result = conn.execute(query).fetchdf()\n",
    "print(\"Parquet schema : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use duckdb to read partitioned parquet files\n",
    "\n",
    "As we know, the partitioned parquet file does not contains the reference columns. For example, all parquet files in the folder departement=01 will not contain column departement.\n",
    "\n",
    "We need to inform duckdb, how to read the partitioned parquet file correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_immo_single_partition_path = (data_path / \"fr_immo_transactions_dep_partition\").as_posix()\n",
    "fr_immo_multi_partition_path = (data_path / \"fr_immo_transactions_multi_partition\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet schema : \n",
      "   id_transaction           date_transaction      prix  id_ville  \\\n",
      "0          141653 2013-12-31 09:25:51.804819  197000.0       427   \n",
      "1          141970 2013-12-31 09:25:51.804819  157500.0       451   \n",
      "2          139240 2013-12-31 09:25:51.804819  112000.0       365   \n",
      "3          146016 2013-12-31 09:25:51.804819  173020.0       202   \n",
      "4          145911 2014-01-01 09:25:43.165683   88000.0       283   \n",
      "\n",
      "                  ville  code_postal                      adresse  \\\n",
      "0               TREVOUX         1600           6346 MTE DES LILAS   \n",
      "1                VIRIAT         1440       1369 RTE DE STRASBOURG   \n",
      "2  SAINT-JEAN-SUR-VEYLE         1290   5174  SAINT JEAN SUR VEYLE   \n",
      "3               LAGNIEU         1150  21 GR GRANDE RUE DE BULLIEZ   \n",
      "4               OYONNAX         1100          29B RUE DE LA FORGE   \n",
      "\n",
      "  type_batiment  n_pieces  surface_habitable   latitude  longitude departement  \n",
      "0   Appartement         4                 84  45.942301   4.770694          01  \n",
      "1        Maison         4                103  46.236407   5.262935          01  \n",
      "2        Maison         3                 78  46.260077   4.918612          01  \n",
      "3        Maison         4                 72  45.899045   5.354220          01  \n",
      "4   Appartement         3                104  46.258408   5.640803          01  \n"
     ]
    }
   ],
   "source": [
    "# read a single partition parquet file with the option hive partition = true\n",
    "query = f\"SELECT * FROM read_parquet('{fr_immo_single_partition_path}/*/*.parquet', hive_partitioning=true);\"\n",
    "result = conn.execute(query).fetchdf()\n",
    "print(\"Parquet schema : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet schema : \n",
      "   id_transaction           date_transaction      prix  id_ville  \\\n",
      "0          141653 2013-12-31 09:25:51.804819  197000.0       427   \n",
      "1          141970 2013-12-31 09:25:51.804819  157500.0       451   \n",
      "2          139240 2013-12-31 09:25:51.804819  112000.0       365   \n",
      "3          146016 2013-12-31 09:25:51.804819  173020.0       202   \n",
      "4          145911 2014-01-01 09:25:43.165683   88000.0       283   \n",
      "\n",
      "                  ville  code_postal                      adresse  \\\n",
      "0               TREVOUX         1600           6346 MTE DES LILAS   \n",
      "1                VIRIAT         1440       1369 RTE DE STRASBOURG   \n",
      "2  SAINT-JEAN-SUR-VEYLE         1290   5174  SAINT JEAN SUR VEYLE   \n",
      "3               LAGNIEU         1150  21 GR GRANDE RUE DE BULLIEZ   \n",
      "4               OYONNAX         1100          29B RUE DE LA FORGE   \n",
      "\n",
      "  type_batiment  n_pieces  surface_habitable   latitude  longitude  \n",
      "0   Appartement         4                 84  45.942301   4.770694  \n",
      "1        Maison         4                103  46.236407   5.262935  \n",
      "2        Maison         3                 78  46.260077   4.918612  \n",
      "3        Maison         4                 72  45.899045   5.354220  \n",
      "4   Appartement         3                104  46.258408   5.640803  \n"
     ]
    }
   ],
   "source": [
    "# read a single partition parquet file with the option hive partition = true\n",
    "query = f\"SELECT * FROM read_parquet('{fr_immo_single_partition_path}/*/*.parquet', hive_partitioning=false);\"\n",
    "result = conn.execute(query).fetchdf()\n",
    "print(\"Parquet schema : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can notice the result for seconde query does not contain the column **departement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet schema : \n",
      "   id_transaction           date_transaction      prix  id_ville  \\\n",
      "0          141653 2013-12-31 09:25:51.804819  197000.0       427   \n",
      "1          145911 2014-01-01 09:25:43.165683   88000.0       283   \n",
      "2          145399 2014-01-01 09:25:43.165683   68000.0        53   \n",
      "3          143192 2014-01-01 09:25:43.165683  156750.0        53   \n",
      "4          146426 2014-01-01 09:25:43.165683  163640.0       376   \n",
      "\n",
      "                      ville  code_postal                adresse  n_pieces  \\\n",
      "0                   TREVOUX         1600     6346 MTE DES LILAS         4   \n",
      "1                   OYONNAX         1100    29B RUE DE LA FORGE         3   \n",
      "2           BOURG-EN-BRESSE         1000  10Z RUE EDGAR  QUINET         2   \n",
      "3           BOURG-EN-BRESSE         1000    15 RUE DE MONTHOLON         3   \n",
      "4  SAINT-MAURICE-DE-BEYNOST         1700         40 AV DES ILES         3   \n",
      "\n",
      "   surface_habitable   latitude  longitude departement type_batiment  \n",
      "0                 84  45.942301   4.770694          01   Appartement  \n",
      "1                104  46.258408   5.640803          01   Appartement  \n",
      "2                 44  46.203859   5.225693          01   Appartement  \n",
      "3                 83  46.200084   5.210837          01   Appartement  \n",
      "4                 84  45.823289   4.977199          01   Appartement  \n"
     ]
    }
   ],
   "source": [
    "# read a two level partition parquet file\n",
    "query = f\"SELECT * FROM read_parquet('{fr_immo_multi_partition_path}/*/*/*.parquet', hive_partitioning=true);\"\n",
    "result = conn.execute(query).fetchdf()\n",
    "print(\"Parquet schema : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet schema : \n",
      "   id_transaction           date_transaction      prix  id_ville  \\\n",
      "0          141653 2013-12-31 09:25:51.804819  197000.0       427   \n",
      "1          145911 2014-01-01 09:25:43.165683   88000.0       283   \n",
      "2          145399 2014-01-01 09:25:43.165683   68000.0        53   \n",
      "3          143192 2014-01-01 09:25:43.165683  156750.0        53   \n",
      "4          146426 2014-01-01 09:25:43.165683  163640.0       376   \n",
      "\n",
      "                      ville  code_postal                adresse  n_pieces  \\\n",
      "0                   TREVOUX         1600     6346 MTE DES LILAS         4   \n",
      "1                   OYONNAX         1100    29B RUE DE LA FORGE         3   \n",
      "2           BOURG-EN-BRESSE         1000  10Z RUE EDGAR  QUINET         2   \n",
      "3           BOURG-EN-BRESSE         1000    15 RUE DE MONTHOLON         3   \n",
      "4  SAINT-MAURICE-DE-BEYNOST         1700         40 AV DES ILES         3   \n",
      "\n",
      "   surface_habitable   latitude  longitude  \n",
      "0                 84  45.942301   4.770694  \n",
      "1                104  46.258408   5.640803  \n",
      "2                 44  46.203859   5.225693  \n",
      "3                 83  46.200084   5.210837  \n",
      "4                 84  45.823289   4.977199  \n"
     ]
    }
   ],
   "source": [
    "# read a two level partition parquet file\n",
    "query = f\"SELECT * FROM read_parquet('{fr_immo_multi_partition_path}/*/*/*.parquet', hive_partitioning=false);\"\n",
    "result = conn.execute(query).fetchdf()\n",
    "print(\"Parquet schema : \")\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can notice the result for seconde query does not contain the column **departement** and **type_batiment**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duck_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
